{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daeaee3a-11f0-499c-bf7a-19c2b2b6b9c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (2.4.2)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.9/site-packages (1.21.5)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.9/site-packages (1.0.2)\nRequirement already satisfied: xgboost in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (1.7.6)\nRequirement already satisfied: hyperopt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (0.2.7)\nRequirement already satisfied: gunicorn<21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (20.1.0)\nRequirement already satisfied: docker<7,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (6.1.3)\nRequirement already satisfied: pytz<2024 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2021.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (6.0)\nRequirement already satisfied: gitpython<4,>=2.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (3.1.31)\nRequirement already satisfied: cloudpickle<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.19.4)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2.27.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (1.11.1)\nRequirement already satisfied: Jinja2<4,>=2.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.7.3)\nRequirement already satisfied: Flask<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (2.3.2)\nRequirement already satisfied: pyarrow<13,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.5.1)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (0.4)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.4.2)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (6.8.0)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (2.0.18)\nRequirement already satisfied: packaging<24 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (21.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (0.4.4)\nRequirement already satisfied: databricks-cli<1,>=0.8.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (0.17.7)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from mlflow) (8.1.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn) (1.1.1)\nRequirement already satisfied: networkx>=2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from hyperopt) (3.1)\nRequirement already satisfied: future in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from hyperopt) (0.18.3)\nRequirement already satisfied: py4j in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from hyperopt) (0.10.9.7)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from hyperopt) (4.65.0)\nRequirement already satisfied: six in /databricks/python3/lib/python3.9/site-packages (from hyperopt) (1.16.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.4)\nRequirement already satisfied: typing-extensions>=4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.7.1)\nRequirement already satisfied: urllib3<2.0.0,>=1.26.7 in /databricks/python3/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.9)\nRequirement already satisfied: tabulate>=0.7.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\nRequirement already satisfied: pyjwt>=1.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.7.0)\nRequirement already satisfied: websocket-client>=0.32.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.6.1)\nRequirement already satisfied: Werkzeug>=2.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from Flask<3->mlflow) (2.3.6)\nRequirement already satisfied: itsdangerous>=2.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from Flask<3->mlflow) (2.1.2)\nRequirement already satisfied: blinker>=1.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from Flask<3->mlflow) (1.6.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\nRequirement already satisfied: setuptools>=3.0 in /databricks/python3/lib/python3.9/site-packages (from gunicorn<21->mlflow) (61.2.0)\nRequirement already satisfied: zipp>=0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (9.0.1)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2021.10.8)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9b02d93e-3432-47a4-8534-9903bd950d35/lib/python3.9/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow numpy scikit-learn xgboost hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6feae985-fe81-4b64-a26d-2a90b878b1d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import cloudpickle\n",
    "import time\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1). \n",
    "# The following code creates a wrapper function, SklearnModelWrapper, that uses \n",
    "# the predict_proba method to return the probability that the observation belongs to each class. \n",
    "\n",
    "    \n",
    "# take the data path as a parameter\n",
    "dbutils.widgets.text(\"data_path\", \"\")\n",
    "data_path = dbutils.widgets.get(\"data_path\")\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Split input and output values\n",
    "X = data.drop([\"quality\"], axis=1)\n",
    "y = data.quality\n",
    "\n",
    "# Split out the training data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.6, random_state=123)\n",
    "\n",
    "# Split the remaining data equally into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1925445-58f1-4d10-beb7-ed833b6122c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]\r                                                     \r[0]\tvalidation-rmse:0.42511\n\r  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]\r                                                     \r[1]\tvalidation-rmse:0.38254\n\r  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]\r100%|██████████| 1/1 [00:00<00:00, 26.59trial/s, best loss: -0.8354791517001917]\n{'max_depth': 7}\n[0]\tvalidation-rmse:0.42511\n[1]\tvalidation-rmse:0.38254\n[0]\tvalidation-rmse:0.42511\n[1]\tvalidation-rmse:0.38254\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/10 09:53:13 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.4.2/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(\"/Users/ganendra.vadlamu@tigeranalytics.com/wine_quality\")\n",
    "\n",
    "current_run = mlflow.active_run()\n",
    "\n",
    "if current_run is not None:\n",
    "    # Get the current run ID\n",
    "    run_id = current_run.info.run_id\n",
    "\n",
    "    # Get the previous run's name\n",
    "    previous_run_name = mlflow.get_run(run_id).data.tags.get(\"mlflow.runName\")\n",
    "\n",
    "    # Increment the run name\n",
    "    if previous_run_name:\n",
    "        # Extract the run number from the previous run's name\n",
    "        previous_run_number = int(previous_run_name.split(\"_\")[-1])\n",
    "\n",
    "        # Increment the run number\n",
    "        new_run_number = previous_run_number + 1\n",
    "\n",
    "        # Create the new run name\n",
    "        new_run_name = f\"xgboost_run_{new_run_number}\"\n",
    "    else:\n",
    "        # If there is no previous run name, start with Run_1\n",
    "        new_run_name = \"xgboost_run_1\"\n",
    "\n",
    "    # Set the new run name\n",
    "    mlflow.set_tag(\"mlflow.runName\", new_run_name)\n",
    "\n",
    "    run_name = new_run_name\n",
    "else:\n",
    "    # Start a new MLflow run if there is no active run\n",
    "    run_name = \"xgboost_run_1\"\n",
    "\n",
    "# Function to train an XGBoost model\n",
    "def train_xgboost(params):\n",
    "    train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    validation = xgb.DMatrix(data=X_test, label=y_test)\n",
    "    model = xgb.train(params=params, dtrain=train, num_boost_round=2, evals=[(validation, \"validation\")],\n",
    "                      early_stopping_rounds=2)\n",
    "    predictions = model.predict(validation)\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    return {'status': STATUS_OK, 'loss': -auc, 'model': model}\n",
    "\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    'max_depth': hp.randint('max_depth', 1, 11),  # Set the range for max_depth\n",
    "}\n",
    "\n",
    "# Start a new MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Perform hyperparameter tuning using Bayesian optimization\n",
    "    best = fmin(fn=train_xgboost, space=search_space, algo=tpe.suggest, max_evals=1, trials=Trials())\n",
    "    print(best)\n",
    "    # Retrieve the best hyperparameters and train the final model\n",
    "    best_max_depth = int(best['max_depth'])\n",
    "\n",
    "    best_params = {\n",
    "        'max_depth': best_max_depth,\n",
    "    }\n",
    "\n",
    "    best_model = train_xgboost(best_params)['model']\n",
    "    xgb_best_auc=train_xgboost(best_params)['loss']\n",
    "    # Log the best hyperparameters and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.xgboost.log_model(best_model, \"model\")   \n",
    "    mlflow.log_metric(\"auc\", xgb_best_auc)\n",
    "    \n",
    "    dmatrix = xgb.DMatrix(X_test)\n",
    "    # Compare the AUC score of the current production model and the best model\n",
    "    production_model = mlflow.pyfunc.load_model(\"models:/wine_quality/production\")\n",
    "    production_auc = roc_auc_score(y_test, production_model.predict(X_test))\n",
    "    best_model_auc = roc_auc_score(y_test, best_model.predict(dmatrix))\n",
    "        # If the best model has a higher AUC score than the production model, archive the production model\n",
    "    if best_model_auc > production_auc:\n",
    "        production_model_version = mlflow.search_registered_models(\"wine_quality\")[0].latest_versions[0]\n",
    "        mlflow.register_model(f\"runs:/{production_model_version.source}/model\", \"archived_production_model\")\n",
    "\n",
    "        # Transition the best model to production\n",
    "        best_model_version = mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/model\", \"production\")\n",
    "        mlflow.pyfunc.update_registered_model(\"wine_quality\", production_model_version.version, stage=\"archived\")\n",
    "        mlflow.pyfunc.update_registered_model(\"wine_quality\", best_model_version.version, stage=\"production\")\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "    # To simulate a new corpus of data, save the existing X_train data to a Delta table. \n",
    "    # In the real world, this would be a new batch of data.\n",
    "    spark_df = spark.createDataFrame(X_train)\n",
    "    # Replace <username> with your username before running this cell.\n",
    "    table_path = \"dbfs:/ganendra.vadlamu@tigeranalytics.com/delta/wine_data\"\n",
    "    # Delete the contents of this path in case this cell has already been run\n",
    "    dbutils.fs.rm(table_path, True)\n",
    "    spark_df.write.format(\"delta\").save(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49266d16-f03e-46bf-b259-5b1b0f3f2915",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Specify the name of the registered model to delete\n",
    "model_name = \"wine_quality\"\n",
    "\n",
    "We can specify list of version and loop through each to move stage to Archived and then call delete registered model\n",
    "to delete the registered models\n",
    "client.transition_model_version_stage(\n",
    "  name=model_name,\n",
    "  version=6,\n",
    "  stage=\"Archived\",\n",
    ")\n",
    "\n",
    "# Delete the registered models\n",
    "client = MlflowClient()\n",
    "\n",
    "client.delete_registered_model(name=model_name)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15a134fb-f22b-4f13-bab0-112c67d91f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "\n",
    "\n",
    "class SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "    \n",
    "  def predict(self, context, model_input):\n",
    "    return self.model.predict_proba(model_input)[:,1]\n",
    "\t\n",
    "mlflow.set_experiment(\"/Users/ganendra.vadlamu@tigeranalytics.com/wine_quality\")\n",
    "\n",
    "current_run = mlflow.active_run()\n",
    "\n",
    "if current_run is not None:\n",
    "    # Get the current run ID\n",
    "    run_id = current_run.info.run_id\n",
    "\n",
    "    # Get the previous run's name\n",
    "    previous_run_name = mlflow.get_run(run_id).data.tags.get(\"mlflow.runName\")\n",
    "\n",
    "    # Increment the run name\n",
    "    if previous_run_name:\n",
    "        # Extract the run number from the previous run's name\n",
    "        previous_run_number = int(previous_run_name.split(\"_\")[-1])\n",
    "\n",
    "        # Increment the run number\n",
    "        new_run_number = previous_run_number + 1\n",
    "\n",
    "        # Create the new run name\n",
    "        new_run_name = f\"random_forest_untuned_run_{new_run_number}\"\n",
    "    else:\n",
    "        # If there is no previous run name, start with Run_1\n",
    "        new_run_name = \"random_forest_untuned_run_1\"\n",
    "\n",
    "    # Set the new run name\n",
    "    mlflow.set_tag(\"mlflow.runName\", new_run_name)\n",
    "\n",
    "    run_name=new_run_name\n",
    "else:\n",
    "    # Start a new MLflow run if there is no active run\n",
    "    run_name=\"random_forest_untuned_run_1\"\n",
    "\n",
    "\n",
    "# mlflow.start_run creates a new MLflow run to track the performance of this model. \n",
    "# Within the context, you call mlflow.log_param to keep track of the parameters used, and\n",
    "# mlflow.log_metric to record metrics like accuracy.\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "  n_estimators = 10\n",
    "  model = RandomForestClassifier(n_estimators=n_estimators, random_state=np.random.RandomState(123))\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]\n",
    "  predictions_test = model.predict_proba(X_test)[:,1]\n",
    "  auc_score = roc_auc_score(y_test, predictions_test)\n",
    "  mlflow.log_param('n_estimators', n_estimators)\n",
    "  # Use the area under the ROC curve as a metric.\n",
    "  mlflow.log_metric('auc', auc_score)\n",
    "  wrappedModel = SklearnModelWrapper(model)\n",
    "  # Log the model with a signature that defines the schema of the model's inputs and outputs. \n",
    "  # When the model is deployed, this signature will be used to validate inputs.\n",
    "  signature = infer_signature(X_train, wrappedModel.predict(None, X_train))\n",
    "  \n",
    "  # MLflow contains utilities to create a conda environment used to serve models.\n",
    "  # The necessary dependencies are added to a conda.yaml file which is logged along with the model.\n",
    "  conda_env =  _mlflow_conda_env(\n",
    "        additional_conda_deps=None,\n",
    "        additional_pip_deps=[\"cloudpickle=={}\".format(cloudpickle.__version__), \"scikit-learn=={}\".format(sklearn.__version__)],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "  mlflow.pyfunc.log_model(\"random_forest_model\", python_model=wrappedModel, conda_env=conda_env, signature=signature)\n",
    "\n",
    "  feature_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns.tolist(), columns=['importance'])\n",
    "feature_importances.sort_values('importance', ascending=False)\n",
    "#model registry\n",
    "run_id = mlflow.search_runs(filter_string='tags.mlflow.runName LIKE  \"random_forest_untuned_run%\"').iloc[0].run_id\n",
    "\n",
    "# If you see the error \"PERMISSION_DENIED: User does not have any permission level assigned to the registered model\", \n",
    "# the cause may be that a model already exists with the name \"wine_quality\". Try using a different name.\n",
    "model_name = \"wine_quality\"\n",
    "model_version = mlflow.register_model(f\"runs:/{run_id}/random_forest_model\", model_name)\n",
    "\n",
    "# Registering the model takes a few seconds, so add a small delay\n",
    "time.sleep(15)\n",
    "\n",
    "#registering the model to production\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "  name=model_name,\n",
    "  version=model_version.version,\n",
    "  stage=\"Production\",\n",
    ")\n",
    "\n",
    "model = mlflow.pyfunc.load_model(f\"models:/{model_name}/production\")\n",
    "\n",
    "# Sanity-check: This should match the AUC logged by MLflow\n",
    "print(f'AUC: {roc_auc_score(y_test, model.predict(X_test))}')\n",
    "\n",
    "# To simulate a new corpus of data, save the existing X_train data to a Delta table. \n",
    "# In the real world, this would be a new batch of data.\n",
    "spark_df = spark.createDataFrame(X_train)\n",
    "# Replace <username> with your username before running this cell.\n",
    "table_path = \"dbfs:/ganendra.vadlamu@tigeranalytics.com/delta/wine_data\"\n",
    "# Delete the contents of this path in case this cell has already been run\n",
    "dbutils.fs.rm(table_path, True)\n",
    "spark_df.write.format(\"delta\").save(table_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac4db0b-f3e1-4af3-9164-b5669670f223",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "model_training",
   "widgets": {
    "data_path": {
     "currentValue": "/dbfs/FileStore/shared_uploads/ganendra.vadlamu@tigeranalytics.com/preprocessed_data.csv",
     "nuid": "f77a2ecf-4ecd-4eb2-903a-e8e76f099b5d",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "data_path",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
